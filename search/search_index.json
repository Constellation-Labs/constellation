{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Documentation for the Constellation Labs DAG project. Source available on Github . More information in the docs folder and the github wiki .","title":"Introduction"},{"location":"#introduction","text":"Documentation for the Constellation Labs DAG project. Source available on Github . More information in the docs folder and the github wiki .","title":"Introduction"},{"location":"architecture/","text":"Architecture documentation Diagrams ledger architecture node-architecture protocol-data-flow-sketch","title":"Architecture"},{"location":"architecture/#architecture-documentation","text":"","title":"Architecture documentation"},{"location":"architecture/#diagrams","text":"","title":"Diagrams"},{"location":"architecture/#ledger-architecture","text":"","title":"ledger architecture"},{"location":"architecture/#node-architecture","text":"","title":"node-architecture"},{"location":"architecture/#protocol-data-flow-sketch","text":"","title":"protocol-data-flow-sketch"},{"location":"design-choices/","text":"Design choices This file summarizes current reasoning for our approach and design decisions, reviews and references. Many decisions can be traced back to the fundamental goal to provide an accessible, scalable protocol that focuses on solving the consensus task. For a glimpse into the teams perspectives, you may check out the following video clips: youtube.com/constellation-labs/talk-at-Scale-By-The-Bay (Nov. 2018, 22 mins) youtube.com/constellation-labs/talk-at-Tech-Crunch (Oct. 2018, 28 mins) youtube.com/constellation-labs/testnet-overview (Aug. 2018, 22 mins) Why Scala? There are some general notes on Scala and also on other functional programming languages actively used for crypto projects in the /wiki/Comparisons-to-other-protocols . One motivating factor as a language of choice for the reference implementation of the protocol was of course the core teams experience with it, as well as the useful packages like akka actors and apache spark on the Java virtual machine (JVM). The constellation code base also makes extensive use of the type hierarchy features. In fact, the para-protocol approach to dApp integration builds on it. On the architecture For diagrams, see /docs/architecture.md . Feedback Please communicate suggestions by making a thread on the community portal Orion or approaching the developers on the discord server:","title":"Design choices"},{"location":"design-choices/#design-choices","text":"This file summarizes current reasoning for our approach and design decisions, reviews and references. Many decisions can be traced back to the fundamental goal to provide an accessible, scalable protocol that focuses on solving the consensus task. For a glimpse into the teams perspectives, you may check out the following video clips: youtube.com/constellation-labs/talk-at-Scale-By-The-Bay (Nov. 2018, 22 mins) youtube.com/constellation-labs/talk-at-Tech-Crunch (Oct. 2018, 28 mins) youtube.com/constellation-labs/testnet-overview (Aug. 2018, 22 mins)","title":"Design choices"},{"location":"design-choices/#why-scala","text":"There are some general notes on Scala and also on other functional programming languages actively used for crypto projects in the /wiki/Comparisons-to-other-protocols . One motivating factor as a language of choice for the reference implementation of the protocol was of course the core teams experience with it, as well as the useful packages like akka actors and apache spark on the Java virtual machine (JVM). The constellation code base also makes extensive use of the type hierarchy features. In fact, the para-protocol approach to dApp integration builds on it.","title":"Why Scala?"},{"location":"design-choices/#on-the-architecture","text":"For diagrams, see /docs/architecture.md .","title":"On the architecture"},{"location":"design-choices/#feedback","text":"Please communicate suggestions by making a thread on the community portal Orion or approaching the developers on the discord server:","title":"Feedback"},{"location":"running-a-node/","text":"Running a node Constellation nodes are currently released as JAR file. You can always find the latest one on constellation/releases page. It can be run on any system supporting Java 8 or higher. Download release Releases are currently distributed as Java JAR files. Download the latest from github. Node Requirements To run a constellation node, you'll need a machine with java 8 or higher installed. While we expect that running on Windows will work, we have only internally tested on MacOS and Linux. Instance specs: We haven't spent much time optimizing for resource usage, so these specs are higher than we anticipate at mainnet. Currently, for testnet, we recommend: CPU: 2-core minimum. Memory: 3GB or higher Disk: 200GB available. Node Configuration Nodes can be configured in two ways. Some options are available through the cmdline, and more extensive options are available by supplying a configuration file. There is a default configuration file , but the options in it can be overriden by providing an additional conf file. The format is HOCON from Lightbend Config but is essentially a superset of YAML & JSON. We intend to document available configuration options in more depth soon. Port Configuration A constellation node has two API's: A control API meant for the node operator to make changes to node operation, and a data (or peer) API, used by nodes to communicate with each other. By default, the control API uses port 9000, and the peer API uses port 9001. These can be overridden in the node configuration, but whatever they are set to, these ports must be open and exposed to the public internet. Connecting To An Existing Network The most important configuration to connect to our testnet is providing a seed node to connect to. The easiest way to do this right now is to set it with an environment variable (example ip only, don't use): export DAG_SEED_PEER=123.456.123.456:9001 We are not currently running any publicly joinable network -- please get in touch on Telegram or Discord if you'd like to connect a node to our testnet network. Where to Run Running a node at home While running a from your home internet is possible, it's not a supported or recommended setup. It can be difficult to properly expose ports on your computer to the public internet, because home networking equipment like modems and routers often have firewalls blocking these ports, and often home networks do not have a stable ip address. For now, our official recommendation is to use a cloud provider. Cloud hosting As a team we have the most expertise with Google Cloud, and it is our recommended platform for those without one already, but any cloud provider will work. On Google Cloud Platform (GCP), choose compute engine using a Ubuntu or Debian machine. You can also do the installations up on the cloud machine. Make sure the relevant ports are open / not firewalled. Cloud providers Any cloud provider should work fine. While we do all our testing on GCP (Google Cloud Provider), we are not using any proprietary features. If you can launch a machine, install java 8 or higher, assign an external IP, and open the ports for the control API and peer API, you shouldn't have any problems. Manual Builds And Deployment The build instructions have more pointers on how to run a node. Additional Tools Check out the recommended tools and frameworks section in the docks. Here we highlight two: Docker We intend to have official docker images soon -- stay tuned. Terraform (Optional!) At Constellation Labs we use terraform to quickly launch and destroy clusters for testing. Our terraform configurations are checked in to the repository in the terraform directory, so they are available as a guide if you'd like to use it yourself. They automate some nice but optional things like running the node as a service. They are currently setup for GCP, and they have a few constellation-specific hardcoded variables (backend storage location, project name). That said -- if you're familiar with terraform, they should be straightforward to adapt for your uses. While we are not officially supporting this right now, we can provide some support on discord for this method.","title":"Running a node"},{"location":"running-a-node/#running-a-node","text":"Constellation nodes are currently released as JAR file. You can always find the latest one on constellation/releases page. It can be run on any system supporting Java 8 or higher.","title":"Running a node"},{"location":"running-a-node/#download-release","text":"Releases are currently distributed as Java JAR files. Download the latest from github.","title":"Download release"},{"location":"running-a-node/#node-requirements","text":"To run a constellation node, you'll need a machine with java 8 or higher installed. While we expect that running on Windows will work, we have only internally tested on MacOS and Linux.","title":"Node Requirements"},{"location":"running-a-node/#instance-specs","text":"We haven't spent much time optimizing for resource usage, so these specs are higher than we anticipate at mainnet. Currently, for testnet, we recommend: CPU: 2-core minimum. Memory: 3GB or higher Disk: 200GB available.","title":"Instance specs:"},{"location":"running-a-node/#node-configuration","text":"Nodes can be configured in two ways. Some options are available through the cmdline, and more extensive options are available by supplying a configuration file. There is a default configuration file , but the options in it can be overriden by providing an additional conf file. The format is HOCON from Lightbend Config but is essentially a superset of YAML & JSON. We intend to document available configuration options in more depth soon.","title":"Node Configuration"},{"location":"running-a-node/#port-configuration","text":"A constellation node has two API's: A control API meant for the node operator to make changes to node operation, and a data (or peer) API, used by nodes to communicate with each other. By default, the control API uses port 9000, and the peer API uses port 9001. These can be overridden in the node configuration, but whatever they are set to, these ports must be open and exposed to the public internet.","title":"Port Configuration"},{"location":"running-a-node/#connecting-to-an-existing-network","text":"The most important configuration to connect to our testnet is providing a seed node to connect to. The easiest way to do this right now is to set it with an environment variable (example ip only, don't use): export DAG_SEED_PEER=123.456.123.456:9001 We are not currently running any publicly joinable network -- please get in touch on Telegram or Discord if you'd like to connect a node to our testnet network.","title":"Connecting To An Existing Network"},{"location":"running-a-node/#where-to-run","text":"","title":"Where to Run"},{"location":"running-a-node/#running-a-node-at-home","text":"While running a from your home internet is possible, it's not a supported or recommended setup. It can be difficult to properly expose ports on your computer to the public internet, because home networking equipment like modems and routers often have firewalls blocking these ports, and often home networks do not have a stable ip address. For now, our official recommendation is to use a cloud provider.","title":"Running a node at home"},{"location":"running-a-node/#cloud-hosting","text":"As a team we have the most expertise with Google Cloud, and it is our recommended platform for those without one already, but any cloud provider will work. On Google Cloud Platform (GCP), choose compute engine using a Ubuntu or Debian machine. You can also do the installations up on the cloud machine. Make sure the relevant ports are open / not firewalled.","title":"Cloud hosting"},{"location":"running-a-node/#cloud-providers","text":"Any cloud provider should work fine. While we do all our testing on GCP (Google Cloud Provider), we are not using any proprietary features. If you can launch a machine, install java 8 or higher, assign an external IP, and open the ports for the control API and peer API, you shouldn't have any problems.","title":"Cloud providers"},{"location":"running-a-node/#manual-builds-and-deployment","text":"The build instructions have more pointers on how to run a node.","title":"Manual Builds And Deployment"},{"location":"running-a-node/#additional-tools","text":"Check out the recommended tools and frameworks section in the docks. Here we highlight two:","title":"Additional Tools"},{"location":"running-a-node/#docker","text":"We intend to have official docker images soon -- stay tuned.","title":"Docker"},{"location":"running-a-node/#terraform-optional","text":"At Constellation Labs we use terraform to quickly launch and destroy clusters for testing. Our terraform configurations are checked in to the repository in the terraform directory, so they are available as a guide if you'd like to use it yourself. They automate some nice but optional things like running the node as a service. They are currently setup for GCP, and they have a few constellation-specific hardcoded variables (backend storage location, project name). That said -- if you're familiar with terraform, they should be straightforward to adapt for your uses. While we are not officially supporting this right now, we can provide some support on discord for this method.","title":"Terraform (Optional!)"},{"location":"transaction-validation/","text":"Transaction Validation Each transaction sent to cluster needs to be validated before proposing it to block/consensus. Part of code responsible for validation is in TransactionValidator.scala . Source signature validation Sender needs to sign transaction by using his private key. Signature of transaction needs to ensure following things: transaction has been signed by known sender sender can't deny signing the transaction nobody altered transaction Validation checks in collection of validation signatures about the edge called signatureBatch if there is such address which equals source address and compares hash with signaturesHash Destination address validation Valid destination wallet address (receiver of tokens) must match the following conditions: Can't be empty Must have DAG prefix Must have at least 30 characters length Must be different from source address The validation of address emptiness happens in validateEmptyDestinationAddress which just checks if address is not empty. In case of failure it returns EmptyDestinationAddress validation result. If address is not empty then validateDestinationAddress is triggered which checks the prefix, length and compares source address with destination address. In case of failure it returns InvalidDestinationAddress . Token amount validation Each transaction contains information about number of tokens to transfer from source address to destination address. The way of validating amount of token differs between dummy and non-dummy transactions. When dummy transaction fails: Number of tokens different than 0 . It is because dummy transaction should not change any of balances so 0 is expected there. In case of failure it returns NonZeroAmount validation result. When non-dummy transaction fails: 0 tokens, in opposite to dummy transaction we must provide positive number of tokens. It causes NonPositiveAmount . Negative number of tokens. It causes NonPositiveAmount as well. Number of tokens bigger than maximum value of Long which causes OverflowAmount validation result. Amount is validated in validateAmount method. Fee validation For fee, we apply similar validation rules as we apply to non-dummy transactions. Transaction does not need to have fee at all but if it exits it can't be: Equal to 0 (because then transaction should not include fee at all). It causes NonPositiveAmount . Negative number of tokens. It causes NonPositiveAmount as well. Duplicated transaction validation Each transaction is unique (identified by unique hash) so sending same transaction twice should fail. Each of nodes stores list of already accepted transactions and sending already accepted one fails with HashDuplicateFound . Validation is being triggered in validateDuplicate method. Last transaction reference validation All transactions sent from particular source address form chain structure where each transaction stores a reference to previous transaction ( lastTxRef field). There is also ordinal field which stores ordinal number which is the index of transaction according to the order. That being said all the transactions need to form a chain by keeping reference to previous transaction and incrementing the ordinal number. The only exception for that statement is the very first transaction because it must have lastTxRef empty (because there is no previous transaction) and ordinal set to 0 (because we start indexing from 0 ). Each of nodes stores information about last accepted transaction for each wallet address and validates received one against it. Validation happens in validateLastTransactionRef and checks couple of things depending on if it is first transaction or one of next ones. For very first transaction: if ordinal is set to 0 if lastTxRef is empty For each next transaction: if lastTxRef is not empty if lastTxRef points to last accepted transaction for that address (to check if transaction chain has no gaps) if ordinal has been incremented properly (it should be +1 to previous ordinal number)","title":"Transaction Validation"},{"location":"transaction-validation/#transaction-validation","text":"Each transaction sent to cluster needs to be validated before proposing it to block/consensus. Part of code responsible for validation is in TransactionValidator.scala .","title":"Transaction Validation"},{"location":"transaction-validation/#source-signature-validation","text":"Sender needs to sign transaction by using his private key. Signature of transaction needs to ensure following things: transaction has been signed by known sender sender can't deny signing the transaction nobody altered transaction Validation checks in collection of validation signatures about the edge called signatureBatch if there is such address which equals source address and compares hash with signaturesHash","title":"Source signature validation"},{"location":"transaction-validation/#destination-address-validation","text":"Valid destination wallet address (receiver of tokens) must match the following conditions: Can't be empty Must have DAG prefix Must have at least 30 characters length Must be different from source address The validation of address emptiness happens in validateEmptyDestinationAddress which just checks if address is not empty. In case of failure it returns EmptyDestinationAddress validation result. If address is not empty then validateDestinationAddress is triggered which checks the prefix, length and compares source address with destination address. In case of failure it returns InvalidDestinationAddress .","title":"Destination address validation"},{"location":"transaction-validation/#token-amount-validation","text":"Each transaction contains information about number of tokens to transfer from source address to destination address. The way of validating amount of token differs between dummy and non-dummy transactions. When dummy transaction fails: Number of tokens different than 0 . It is because dummy transaction should not change any of balances so 0 is expected there. In case of failure it returns NonZeroAmount validation result. When non-dummy transaction fails: 0 tokens, in opposite to dummy transaction we must provide positive number of tokens. It causes NonPositiveAmount . Negative number of tokens. It causes NonPositiveAmount as well. Number of tokens bigger than maximum value of Long which causes OverflowAmount validation result. Amount is validated in validateAmount method.","title":"Token amount validation"},{"location":"transaction-validation/#fee-validation","text":"For fee, we apply similar validation rules as we apply to non-dummy transactions. Transaction does not need to have fee at all but if it exits it can't be: Equal to 0 (because then transaction should not include fee at all). It causes NonPositiveAmount . Negative number of tokens. It causes NonPositiveAmount as well.","title":"Fee validation"},{"location":"transaction-validation/#duplicated-transaction-validation","text":"Each transaction is unique (identified by unique hash) so sending same transaction twice should fail. Each of nodes stores list of already accepted transactions and sending already accepted one fails with HashDuplicateFound . Validation is being triggered in validateDuplicate method.","title":"Duplicated transaction validation"},{"location":"transaction-validation/#last-transaction-reference-validation","text":"All transactions sent from particular source address form chain structure where each transaction stores a reference to previous transaction ( lastTxRef field). There is also ordinal field which stores ordinal number which is the index of transaction according to the order. That being said all the transactions need to form a chain by keeping reference to previous transaction and incrementing the ordinal number. The only exception for that statement is the very first transaction because it must have lastTxRef empty (because there is no previous transaction) and ordinal set to 0 (because we start indexing from 0 ). Each of nodes stores information about last accepted transaction for each wallet address and validates received one against it. Validation happens in validateLastTransactionRef and checks couple of things depending on if it is first transaction or one of next ones. For very first transaction: if ordinal is set to 0 if lastTxRef is empty For each next transaction: if lastTxRef is not empty if lastTxRef points to last accepted transaction for that address (to check if transaction chain has no gaps) if ordinal has been incremented properly (it should be +1 to previous ordinal number)","title":"Last transaction reference validation"}]}