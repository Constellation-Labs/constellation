{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Documentation for the Constellation Labs DAG project. Source available on Github . More information in the docs folder and the github wiki .","title":"Introduction"},{"location":"#introduction","text":"Documentation for the Constellation Labs DAG project. Source available on Github . More information in the docs folder and the github wiki .","title":"Introduction"},{"location":"architecture/","text":"Architecture documentation Diagrams ledger architecture node-architecture protocol-data-flow-sketch","title":"Architecture"},{"location":"architecture/#architecture-documentation","text":"","title":"Architecture documentation"},{"location":"architecture/#diagrams","text":"","title":"Diagrams"},{"location":"architecture/#ledger-architecture","text":"","title":"ledger architecture"},{"location":"architecture/#node-architecture","text":"","title":"node-architecture"},{"location":"architecture/#protocol-data-flow-sketch","text":"","title":"protocol-data-flow-sketch"},{"location":"consensus/","text":"Consensus Architecture Every new CheckpointBlock is being created under a consensus round. Glossary consensus owner - the node which sent consensus proposal to others and initiated a new round facilitator - node which has been selected to take part in a new round and responded successfully to participate in it (including owner) SOE - signed observation edge (see: ) data proposal - transactions (and other checkpoint block data) proposed by the facilitator to include in the new consensus round Consensus round Start consensus Broadcast and gather consensus data proposals Merge, broadcast and gather consensus block proposals Select a majority block proposal and merge facilitators' signatures Accept a finished block and broadcast it to non-facilitators Stages 1. Start consensus ConsensusScheduler runs consensusManager.startOwnConsensus() every n seconds ( default value: 10s , configurable under constellation.consensus.start-own-interval ). To start a new round, node must be in one of valid node states. Otherwise, creating new round will be skipped. Valid node states for starting new consensus round are Ready and SnapshotCreation . When new round can be created, owner creates one by using pending transactions (up to maxTransactionThreshold ), tip SOE and selects final facilitators. Peers which can take part in the consensus round must have nextSnapshotHeight below the proposed tip. Otherwise, the selected node will not be able to accept the final checkpoint block. Facilitators are being selected randomly taking into account above preconditions. Dummy transaction is a transaction pulled to the consensus round if node has no real transactions. Node should always be able to create a block, even if the block is empty. To distinguish empty blocks, there must be at least one dummy transaction which is equivalent to the real transaction but carries 0 amount. 2. Broadcast and gather consensus data proposals Owner sends the NotifyFacilitators message to all selected facilitators and waits for the response. If facilitator is able to start a consensus, responds with success message and creates a corresponding round. Facilitator cannot start a consensus if proposed tip is below the next snapshot height or is in the incorrect state (i.e. leaving from the cluster). When all facilitators have been notified and started rounds successfully, each one pulls transactions, similarly as owner did, and broadcasts it to all consensus round's participants. In parallel, each participant gathers proposals from others and keeps it locally. 3. Merge, broadcast and gather consensus block proposals When node receives all proposals, it merges them together to create a block proposal and then broadcasts it to others. Such a block proposal is being signed by the proposer only. The same process happens on every node taking part in a consensus round, hence when data used for block proposal creation are the same, block proposals will be equal (except signatures which obviously must be different). 4. Select a majority block proposal and merge facilitator's signatures When node receives all block proposals, it verifies the correctness of proposals. The majority block is being chosen and all edges from corresponding blocks are merged together creating one block with all signatures. Such a block is broadcasted to other facilitators as selected one. 5. Accept a finished block and broadcast it to non-facilitators When node receives confirmation from other participants that the selected block is the same across all facilitators, it starts acceptance flow for the selected block. If block has been accepted successfully, node broadcasts it to all non-facilitators. It simply means that every other node in the network receives the newly created block and tries to accept it. Clean up Every own and participating consensus round has a total timeout specified by form-checkpoint-blocks-timeout configuration entry. If the round takes longer or basically stopped at some point, the cleaning process will close such round. Transactions and observations proposed in the round will be taken back to the pool and proposed in another round. The same applies if consensus round has been finished with an error. Errors OwnRoundAlreadyInProgress - cannot start a new round because another own one is in progress NoTipsForConsensus - there are no tips to start a new round NoPeersForConsensus - there are no peers to start a new round with NotAllPeersParticipate - one of selected facilitator rejected participating in the round (i.e. when proposed tip is above the latest created snapshot height) NotEnoughProposals - if node receives fewer proposals than expected Configuration consensus { maxTransactionThreshold = 50 maxObservationThreshold = 50 start-own-interval = 5s cleanup-interval = 10s union-proposals-timeout = 10s checkpoint-block-resolve-majority-timeout = 10s form-checkpoint-blocks-timeout = 40s } maxTransactionThreshold ( default : 50 ) - maximum transactions that can be pulled to one round maxObservationThreshold ( default : 50 ) - maximum observations that can be pulled to one round start-own-interval ( default : 5s ) - how often trigger creating new round cleanup-interval ( default : 10s ) - how often trigger cleaning up flow union-proposals-timeout ( default : 10s ) - timeout for gathering data proposals checkpoint-block-resolve-majority-timeout ( default : 10s ) - timeout for gathering block proposals form-checkpoint-blocks-timeout ( default : 40s ) - timeout for the whole consensus round","title":"Consensus"},{"location":"consensus/#consensus","text":"","title":"Consensus"},{"location":"consensus/#architecture","text":"Every new CheckpointBlock is being created under a consensus round.","title":"Architecture"},{"location":"consensus/#glossary","text":"consensus owner - the node which sent consensus proposal to others and initiated a new round facilitator - node which has been selected to take part in a new round and responded successfully to participate in it (including owner) SOE - signed observation edge (see: ) data proposal - transactions (and other checkpoint block data) proposed by the facilitator to include in the new consensus round","title":"Glossary"},{"location":"consensus/#consensus-round","text":"Start consensus Broadcast and gather consensus data proposals Merge, broadcast and gather consensus block proposals Select a majority block proposal and merge facilitators' signatures Accept a finished block and broadcast it to non-facilitators","title":"Consensus round"},{"location":"consensus/#stages","text":"","title":"Stages"},{"location":"consensus/#1-start-consensus","text":"ConsensusScheduler runs consensusManager.startOwnConsensus() every n seconds ( default value: 10s , configurable under constellation.consensus.start-own-interval ). To start a new round, node must be in one of valid node states. Otherwise, creating new round will be skipped. Valid node states for starting new consensus round are Ready and SnapshotCreation . When new round can be created, owner creates one by using pending transactions (up to maxTransactionThreshold ), tip SOE and selects final facilitators. Peers which can take part in the consensus round must have nextSnapshotHeight below the proposed tip. Otherwise, the selected node will not be able to accept the final checkpoint block. Facilitators are being selected randomly taking into account above preconditions. Dummy transaction is a transaction pulled to the consensus round if node has no real transactions. Node should always be able to create a block, even if the block is empty. To distinguish empty blocks, there must be at least one dummy transaction which is equivalent to the real transaction but carries 0 amount.","title":"1. Start consensus"},{"location":"consensus/#2-broadcast-and-gather-consensus-data-proposals","text":"Owner sends the NotifyFacilitators message to all selected facilitators and waits for the response. If facilitator is able to start a consensus, responds with success message and creates a corresponding round. Facilitator cannot start a consensus if proposed tip is below the next snapshot height or is in the incorrect state (i.e. leaving from the cluster). When all facilitators have been notified and started rounds successfully, each one pulls transactions, similarly as owner did, and broadcasts it to all consensus round's participants. In parallel, each participant gathers proposals from others and keeps it locally.","title":"2. Broadcast and gather consensus data proposals"},{"location":"consensus/#3-merge-broadcast-and-gather-consensus-block-proposals","text":"When node receives all proposals, it merges them together to create a block proposal and then broadcasts it to others. Such a block proposal is being signed by the proposer only. The same process happens on every node taking part in a consensus round, hence when data used for block proposal creation are the same, block proposals will be equal (except signatures which obviously must be different).","title":"3. Merge, broadcast and gather consensus block proposals"},{"location":"consensus/#4-select-a-majority-block-proposal-and-merge-facilitators-signatures","text":"When node receives all block proposals, it verifies the correctness of proposals. The majority block is being chosen and all edges from corresponding blocks are merged together creating one block with all signatures. Such a block is broadcasted to other facilitators as selected one.","title":"4. Select a majority block proposal and merge facilitator's signatures"},{"location":"consensus/#5-accept-a-finished-block-and-broadcast-it-to-non-facilitators","text":"When node receives confirmation from other participants that the selected block is the same across all facilitators, it starts acceptance flow for the selected block. If block has been accepted successfully, node broadcasts it to all non-facilitators. It simply means that every other node in the network receives the newly created block and tries to accept it.","title":"5. Accept a finished block and broadcast it to non-facilitators"},{"location":"consensus/#clean-up","text":"Every own and participating consensus round has a total timeout specified by form-checkpoint-blocks-timeout configuration entry. If the round takes longer or basically stopped at some point, the cleaning process will close such round. Transactions and observations proposed in the round will be taken back to the pool and proposed in another round. The same applies if consensus round has been finished with an error.","title":"Clean up"},{"location":"consensus/#errors","text":"OwnRoundAlreadyInProgress - cannot start a new round because another own one is in progress NoTipsForConsensus - there are no tips to start a new round NoPeersForConsensus - there are no peers to start a new round with NotAllPeersParticipate - one of selected facilitator rejected participating in the round (i.e. when proposed tip is above the latest created snapshot height) NotEnoughProposals - if node receives fewer proposals than expected","title":"Errors"},{"location":"consensus/#configuration","text":"consensus { maxTransactionThreshold = 50 maxObservationThreshold = 50 start-own-interval = 5s cleanup-interval = 10s union-proposals-timeout = 10s checkpoint-block-resolve-majority-timeout = 10s form-checkpoint-blocks-timeout = 40s } maxTransactionThreshold ( default : 50 ) - maximum transactions that can be pulled to one round maxObservationThreshold ( default : 50 ) - maximum observations that can be pulled to one round start-own-interval ( default : 5s ) - how often trigger creating new round cleanup-interval ( default : 10s ) - how often trigger cleaning up flow union-proposals-timeout ( default : 10s ) - timeout for gathering data proposals checkpoint-block-resolve-majority-timeout ( default : 10s ) - timeout for gathering block proposals form-checkpoint-blocks-timeout ( default : 40s ) - timeout for the whole consensus round","title":"Configuration"},{"location":"design-choices/","text":"Design choices This file summarizes current reasoning for our approach and design decisions, reviews and references. Many decisions can be traced back to the fundamental goal to provide an accessible, scalable protocol that focuses on solving the consensus task. For a glimpse into the teams perspectives, you may check out the following video clips: youtube.com/constellation-labs/talk-at-Scale-By-The-Bay (Nov. 2018, 22 mins) youtube.com/constellation-labs/talk-at-Tech-Crunch (Oct. 2018, 28 mins) youtube.com/constellation-labs/testnet-overview (Aug. 2018, 22 mins) Why Scala? There are some general notes on Scala and also on other functional programming languages actively used for crypto projects in the /wiki/Comparisons-to-other-protocols . One motivating factor as a language of choice for the reference implementation of the protocol was of course the core teams experience with it, as well as the useful packages like akka actors and apache spark on the Java virtual machine (JVM). The constellation code base also makes extensive use of the type hierarchy features. In fact, the para-protocol approach to dApp integration builds on it. On the architecture For diagrams, see /docs/architecture.md . Feedback Please communicate suggestions by making a thread on the community portal Orion or approaching the developers on the discord server:","title":"Design choices"},{"location":"design-choices/#design-choices","text":"This file summarizes current reasoning for our approach and design decisions, reviews and references. Many decisions can be traced back to the fundamental goal to provide an accessible, scalable protocol that focuses on solving the consensus task. For a glimpse into the teams perspectives, you may check out the following video clips: youtube.com/constellation-labs/talk-at-Scale-By-The-Bay (Nov. 2018, 22 mins) youtube.com/constellation-labs/talk-at-Tech-Crunch (Oct. 2018, 28 mins) youtube.com/constellation-labs/testnet-overview (Aug. 2018, 22 mins)","title":"Design choices"},{"location":"design-choices/#why-scala","text":"There are some general notes on Scala and also on other functional programming languages actively used for crypto projects in the /wiki/Comparisons-to-other-protocols . One motivating factor as a language of choice for the reference implementation of the protocol was of course the core teams experience with it, as well as the useful packages like akka actors and apache spark on the Java virtual machine (JVM). The constellation code base also makes extensive use of the type hierarchy features. In fact, the para-protocol approach to dApp integration builds on it.","title":"Why Scala?"},{"location":"design-choices/#on-the-architecture","text":"For diagrams, see /docs/architecture.md .","title":"On the architecture"},{"location":"design-choices/#feedback","text":"Please communicate suggestions by making a thread on the community portal Orion or approaching the developers on the discord server:","title":"Feedback"},{"location":"running-a-node/","text":"Running a node Constellation nodes are currently released as JAR file. You can always find the latest one on constellation/releases page. It can be run on any system supporting Java 8 or higher. Download release Releases are currently distributed as Java JAR files. Download the latest from github. Node Requirements To run a constellation node, you'll need a machine with java 8 or higher installed. While we expect that running on Windows will work, we have only internally tested on MacOS and Linux. Instance specs: We haven't spent much time optimizing for resource usage, so these specs are higher than we anticipate at mainnet. Currently, for testnet, we recommend: CPU: 2-core minimum. Memory: 3GB or higher Disk: 200GB available. Node Configuration Nodes can be configured in two ways. Some options are available through the cmdline, and more extensive options are available by supplying a configuration file. There is a default configuration file , but the options in it can be overriden by providing an additional conf file. The format is HOCON from Lightbend Config but is essentially a superset of YAML & JSON. We intend to document available configuration options in more depth soon. Port Configuration A constellation node has two API's: A control API meant for the node operator to make changes to node operation, and a data (or peer) API, used by nodes to communicate with each other. By default, the control API uses port 9000, and the peer API uses port 9001. These can be overridden in the node configuration, but whatever they are set to, these ports must be open and exposed to the public internet. Connecting To An Existing Network The most important configuration to connect to our testnet is providing a seed node to connect to. The easiest way to do this right now is to set it with an environment variable (example ip only, don't use): export DAG_SEED_PEER=123.456.123.456:9001 We are not currently running any publicly joinable network -- please get in touch on Telegram or Discord if you'd like to connect a node to our testnet network. Where to Run Running a node at home While running a from your home internet is possible, it's not a supported or recommended setup. It can be difficult to properly expose ports on your computer to the public internet, because home networking equipment like modems and routers often have firewalls blocking these ports, and often home networks do not have a stable ip address. For now, our official recommendation is to use a cloud provider. Cloud hosting As a team we have the most expertise with Google Cloud, and it is our recommended platform for those without one already, but any cloud provider will work. On Google Cloud Platform (GCP), choose compute engine using a Ubuntu or Debian machine. You can also do the installations up on the cloud machine. Make sure the relevant ports are open / not firewalled. Cloud providers Any cloud provider should work fine. While we do all our testing on GCP (Google Cloud Provider), we are not using any proprietary features. If you can launch a machine, install java 8 or higher, assign an external IP, and open the ports for the control API and peer API, you shouldn't have any problems. Manual Builds And Deployment The build instructions have more pointers on how to run a node. Additional Tools Check out the recommended tools and frameworks section in the docks. Here we highlight two: Docker We intend to have official docker images soon -- stay tuned. Terraform (Optional!) At Constellation Labs we use terraform to quickly launch and destroy clusters for testing. Our terraform configurations are checked in to the repository in the terraform directory, so they are available as a guide if you'd like to use it yourself. They automate some nice but optional things like running the node as a service. They are currently setup for GCP, and they have a few constellation-specific hardcoded variables (backend storage location, project name). That said -- if you're familiar with terraform, they should be straightforward to adapt for your uses. While we are not officially supporting this right now, we can provide some support on discord for this method.","title":"Running a node"},{"location":"running-a-node/#running-a-node","text":"Constellation nodes are currently released as JAR file. You can always find the latest one on constellation/releases page. It can be run on any system supporting Java 8 or higher.","title":"Running a node"},{"location":"running-a-node/#download-release","text":"Releases are currently distributed as Java JAR files. Download the latest from github.","title":"Download release"},{"location":"running-a-node/#node-requirements","text":"To run a constellation node, you'll need a machine with java 8 or higher installed. While we expect that running on Windows will work, we have only internally tested on MacOS and Linux.","title":"Node Requirements"},{"location":"running-a-node/#instance-specs","text":"We haven't spent much time optimizing for resource usage, so these specs are higher than we anticipate at mainnet. Currently, for testnet, we recommend: CPU: 2-core minimum. Memory: 3GB or higher Disk: 200GB available.","title":"Instance specs:"},{"location":"running-a-node/#node-configuration","text":"Nodes can be configured in two ways. Some options are available through the cmdline, and more extensive options are available by supplying a configuration file. There is a default configuration file , but the options in it can be overriden by providing an additional conf file. The format is HOCON from Lightbend Config but is essentially a superset of YAML & JSON. We intend to document available configuration options in more depth soon.","title":"Node Configuration"},{"location":"running-a-node/#port-configuration","text":"A constellation node has two API's: A control API meant for the node operator to make changes to node operation, and a data (or peer) API, used by nodes to communicate with each other. By default, the control API uses port 9000, and the peer API uses port 9001. These can be overridden in the node configuration, but whatever they are set to, these ports must be open and exposed to the public internet.","title":"Port Configuration"},{"location":"running-a-node/#connecting-to-an-existing-network","text":"The most important configuration to connect to our testnet is providing a seed node to connect to. The easiest way to do this right now is to set it with an environment variable (example ip only, don't use): export DAG_SEED_PEER=123.456.123.456:9001 We are not currently running any publicly joinable network -- please get in touch on Telegram or Discord if you'd like to connect a node to our testnet network.","title":"Connecting To An Existing Network"},{"location":"running-a-node/#where-to-run","text":"","title":"Where to Run"},{"location":"running-a-node/#running-a-node-at-home","text":"While running a from your home internet is possible, it's not a supported or recommended setup. It can be difficult to properly expose ports on your computer to the public internet, because home networking equipment like modems and routers often have firewalls blocking these ports, and often home networks do not have a stable ip address. For now, our official recommendation is to use a cloud provider.","title":"Running a node at home"},{"location":"running-a-node/#cloud-hosting","text":"As a team we have the most expertise with Google Cloud, and it is our recommended platform for those without one already, but any cloud provider will work. On Google Cloud Platform (GCP), choose compute engine using a Ubuntu or Debian machine. You can also do the installations up on the cloud machine. Make sure the relevant ports are open / not firewalled.","title":"Cloud hosting"},{"location":"running-a-node/#cloud-providers","text":"Any cloud provider should work fine. While we do all our testing on GCP (Google Cloud Provider), we are not using any proprietary features. If you can launch a machine, install java 8 or higher, assign an external IP, and open the ports for the control API and peer API, you shouldn't have any problems.","title":"Cloud providers"},{"location":"running-a-node/#manual-builds-and-deployment","text":"The build instructions have more pointers on how to run a node.","title":"Manual Builds And Deployment"},{"location":"running-a-node/#additional-tools","text":"Check out the recommended tools and frameworks section in the docks. Here we highlight two:","title":"Additional Tools"},{"location":"running-a-node/#docker","text":"We intend to have official docker images soon -- stay tuned.","title":"Docker"},{"location":"running-a-node/#terraform-optional","text":"At Constellation Labs we use terraform to quickly launch and destroy clusters for testing. Our terraform configurations are checked in to the repository in the terraform directory, so they are available as a guide if you'd like to use it yourself. They automate some nice but optional things like running the node as a service. They are currently setup for GCP, and they have a few constellation-specific hardcoded variables (backend storage location, project name). That said -- if you're familiar with terraform, they should be straightforward to adapt for your uses. While we are not officially supporting this right now, we can provide some support on discord for this method.","title":"Terraform (Optional!)"},{"location":"transaction-validation/","text":"Transaction Validation Each transaction sent to cluster needs to be validated before proposing it to block/consensus. Part of code responsible for validation is in TransactionValidator.scala . Source signature validation Sender needs to sign transaction by using his private key. Signature of transaction needs to ensure following things: transaction has been signed by known sender sender can't deny signing the transaction nobody altered transaction Validation checks in collection of validation signatures about the edge called signatureBatch if there is such address which equals source address and compares hash with signaturesHash Destination address validation Valid destination wallet address (receiver of tokens) must match the following conditions: Can't be empty Must have DAG prefix Must have at least 30 characters length Must be different from source address The validation of address emptiness happens in validateEmptyDestinationAddress which just checks if address is not empty. In case of failure it returns EmptyDestinationAddress validation result. If address is not empty then validateDestinationAddress is triggered which checks the prefix, length and compares source address with destination address. In case of failure it returns InvalidDestinationAddress . Token amount validation Each transaction contains information about number of tokens to transfer from source address to destination address. The way of validating amount of token differs between dummy and non-dummy transactions. When dummy transaction fails: Number of tokens different than 0 . It is because dummy transaction should not change any of balances so 0 is expected there. In case of failure it returns NonZeroAmount validation result. When non-dummy transaction fails: 0 tokens, in opposite to dummy transaction we must provide positive number of tokens. It causes NonPositiveAmount . Negative number of tokens. It causes NonPositiveAmount as well. Number of tokens bigger than maximum value of Long which causes OverflowAmount validation result. Amount is validated in validateAmount method. Fee validation For fee, we apply similar validation rules as we apply to non-dummy transactions. Transaction does not need to have fee at all but if it exits it can't be: Equal to 0 (because then transaction should not include fee at all). It causes NonPositiveAmount . Negative number of tokens. It causes NonPositiveAmount as well. Duplicated transaction validation Each transaction is unique (identified by unique hash) so sending same transaction twice should fail. Each of nodes stores list of already accepted transactions and sending already accepted one fails with HashDuplicateFound . Validation is being triggered in validateDuplicate method. Last transaction reference validation All transactions sent from particular source address form chain structure where each transaction stores a reference to previous transaction ( lastTxRef field). There is also ordinal field which stores ordinal number which is the index of transaction according to the order. That being said all the transactions need to form a chain by keeping reference to previous transaction and incrementing the ordinal number. The only exception for that statement is the very first transaction because it must have lastTxRef empty (because there is no previous transaction) and ordinal set to 0 (because we start indexing from 0 ). Each of nodes stores information about last accepted transaction for each wallet address and validates received one against it. Validation happens in validateLastTransactionRef and checks couple of things depending on if it is first transaction or one of next ones. For very first transaction: if lastTxRef is empty if ordinal is set to 0 For each next transaction: if lastTxRef is not empty if lastTxRef points to last accepted transaction for that address (to check if transaction chain has no gaps) if ordinal has been incremented properly (it should be +1 to previous ordinal number)","title":"Transaction Validation"},{"location":"transaction-validation/#transaction-validation","text":"Each transaction sent to cluster needs to be validated before proposing it to block/consensus. Part of code responsible for validation is in TransactionValidator.scala .","title":"Transaction Validation"},{"location":"transaction-validation/#source-signature-validation","text":"Sender needs to sign transaction by using his private key. Signature of transaction needs to ensure following things: transaction has been signed by known sender sender can't deny signing the transaction nobody altered transaction Validation checks in collection of validation signatures about the edge called signatureBatch if there is such address which equals source address and compares hash with signaturesHash","title":"Source signature validation"},{"location":"transaction-validation/#destination-address-validation","text":"Valid destination wallet address (receiver of tokens) must match the following conditions: Can't be empty Must have DAG prefix Must have at least 30 characters length Must be different from source address The validation of address emptiness happens in validateEmptyDestinationAddress which just checks if address is not empty. In case of failure it returns EmptyDestinationAddress validation result. If address is not empty then validateDestinationAddress is triggered which checks the prefix, length and compares source address with destination address. In case of failure it returns InvalidDestinationAddress .","title":"Destination address validation"},{"location":"transaction-validation/#token-amount-validation","text":"Each transaction contains information about number of tokens to transfer from source address to destination address. The way of validating amount of token differs between dummy and non-dummy transactions. When dummy transaction fails: Number of tokens different than 0 . It is because dummy transaction should not change any of balances so 0 is expected there. In case of failure it returns NonZeroAmount validation result. When non-dummy transaction fails: 0 tokens, in opposite to dummy transaction we must provide positive number of tokens. It causes NonPositiveAmount . Negative number of tokens. It causes NonPositiveAmount as well. Number of tokens bigger than maximum value of Long which causes OverflowAmount validation result. Amount is validated in validateAmount method.","title":"Token amount validation"},{"location":"transaction-validation/#fee-validation","text":"For fee, we apply similar validation rules as we apply to non-dummy transactions. Transaction does not need to have fee at all but if it exits it can't be: Equal to 0 (because then transaction should not include fee at all). It causes NonPositiveAmount . Negative number of tokens. It causes NonPositiveAmount as well.","title":"Fee validation"},{"location":"transaction-validation/#duplicated-transaction-validation","text":"Each transaction is unique (identified by unique hash) so sending same transaction twice should fail. Each of nodes stores list of already accepted transactions and sending already accepted one fails with HashDuplicateFound . Validation is being triggered in validateDuplicate method.","title":"Duplicated transaction validation"},{"location":"transaction-validation/#last-transaction-reference-validation","text":"All transactions sent from particular source address form chain structure where each transaction stores a reference to previous transaction ( lastTxRef field). There is also ordinal field which stores ordinal number which is the index of transaction according to the order. That being said all the transactions need to form a chain by keeping reference to previous transaction and incrementing the ordinal number. The only exception for that statement is the very first transaction because it must have lastTxRef empty (because there is no previous transaction) and ordinal set to 0 (because we start indexing from 0 ). Each of nodes stores information about last accepted transaction for each wallet address and validates received one against it. Validation happens in validateLastTransactionRef and checks couple of things depending on if it is first transaction or one of next ones. For very first transaction: if lastTxRef is empty if ordinal is set to 0 For each next transaction: if lastTxRef is not empty if lastTxRef points to last accepted transaction for that address (to check if transaction chain has no gaps) if ordinal has been incremented properly (it should be +1 to previous ordinal number)","title":"Last transaction reference validation"}]}